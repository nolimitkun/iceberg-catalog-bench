# Copy this file to .env and fill in values

# Azure ADLS
ADLS_ACCOUNT=

# Iceberg Catalog (Polaris or UC REST)
POLARIS_REST_URI=
POLARIS_WAREHOUSE_URI=
# Delegation header value for REST Catalog (e.g., bearer token or encoded credentials)
ICEBERG_DELEGATION=

# Spark ADLS auth using vended credentials
# Set AZURE_AUTH_TYPE to OAuth. Choose an OAuth provider:
#  - org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider (Managed Identity)
#  - org.apache.hadoop.fs.azurebfs.oauth2.RefreshTokenBasedTokenProvider (custom vended token)
AZURE_AUTH_TYPE=OAuth
AZURE_OAUTH_PROVIDER=org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider
# Optional, for user-assigned MSI
AZURE_MSI_CLIENT_ID=

# Databricks
DATABRICKS_HOST=
DATABRICKS_HTTP_PATH=
DATABRICKS_TOKEN=
# Optional override catalog name (defaults to interop_uc)
DATABRICKS_CATALOG=
UNITY_WAREHOUSE_LOCATION=

# Snowflake
SNOWFLAKE_ACCOUNT=
SNOWFLAKE_USER=
SNOWFLAKE_PASSWORD=
SNOWFLAKE_ROLE=
SNOWFLAKE_WAREHOUSE=
SNOWFLAKE_DATABASE=
POLARIS_CATALOG_NAME=
SNOWFLAKE_EXTERNAL_VOLUME=
POLARIS_BASE_LOCATION_PREFIX=

# PAT Authentication (recommended for MFA accounts)
# SNOWFLAKE_TOKEN=your_personal_access_token

# Key Pair Authentication (alternative to password + MFA)
# SNOWFLAKE_PRIVATE_KEY_PATH=/path/to/private_key.p8
# SNOWFLAKE_PRIVATE_KEY_PASSPHRASE=your_passphrase

# Test namespace override (optional)
INTEROP_NAMESPACE=
